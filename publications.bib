@inproceedings{10.1145/3637528.3671896,
author = {Bernini, Andrea and Silvestri, Fabrizio and Tolomei, Gabriele},
title = {Evading Community Detection via Counterfactual Neighborhood Search},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671896},
doi = {10.1145/3637528.3671896},
abstract = {Community detection techniques are useful for social media platforms to discover tightly connected groups of users who share common interests. However, this functionality often comes at the expense of potentially exposing individuals to privacy breaches by inadvertently revealing their tastes or preferences. Therefore, some users may wish to preserve their anonymity and opt out of community detection for various reasons, such as affiliation with political or religious organizations, without leaving the platform. In this study, we address the challenge of community membership hiding, which involves strategically altering the structural properties of a network graph to prevent one or more nodes from being identified by a given community detection algorithm. We tackle this problem by formulating it as a constrained counterfactual graph objective, and we solve it via deep reinforcement learning. Extensive experiments demonstrate that our method outperforms existing baselines, striking the best balance between accuracy and cost.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {131–140},
numpages = {10},
keywords = {community detection, community membership hiding, counterfactual graph, node deception, node hiding},
location = {Barcelona, Spain},
series = {KDD '24}
}
@inproceedings{pmlr-v258-giorgi25a,
  title = 	 {Natural Language Counterfactual Explanations for Graphs Using Large Language Models},
  author =       {Giorgi, Flavio and Campagnano, Cesare and Silvestri, Fabrizio and Tolomei, Gabriele},
  booktitle = 	 {Proceedings of The 28th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3565--3573},
  year = 	 {2025},
  editor = 	 {Li, Yingzhen and Mandt, Stephan and Agrawal, Shipra and Khan, Emtiyaz},
  volume = 	 {258},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {03--05 May},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v258/main/assets/giorgi25a/giorgi25a.pdf},
  url = 	 {https://proceedings.mlr.press/v258/giorgi25a.html},
  abstract = 	 {Explainable Artificial Intelligence (XAI) has emerged as a critical area of research to unravel the opaque inner logic of (deep) machine learning models.  Among the various XAI techniques proposed in the literature, counterfactual explanations stand out as one of the most promising approaches. However, these “what-if” explanations are frequently complex and technical, making them difficult for non-experts to understand and, more broadly, challenging for humans to interpret. To bridge this gap, in this work, we exploit the power of open-source Large Language Models to generate natural language explanations when prompted with valid counterfactual instances produced by state-of-the-art explainers for graph-based models.  Experiments across several graph datasets and counterfactual explainers show that our approach effectively produces accurate natural language representations of counterfactual instances, as demonstrated by key performance metrics}
}
@article{10.1145/3731683,
author = {Chen, Ziheng and Huang, Jin and Silvestri, Fabrizio and Zhang, Yongfeng and Ahn, Hongshik and Tolomei, Gabriele},
title = {Joint Factual and Counterfactual Explanations for Top-k GNN-based Recommendations},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731683},
doi = {10.1145/3731683},
abstract = {Recently, graph neural networks (GNNs) have become the new state-of-the-art approach to developing powerful recommender systems. However, it is hard for GNN-based recommender systems to attach tangible explanations of why a specific item ends up in the list of top-k suggestions for a given user. Indeed, explaining GNN-based recommendations is unique, and existing GNN explanation methods are inappropriate since they are designed to explain node, edge, or graph classification rather than ranking. In this work, we propose GREASE, a novel method for explaining the list of top-k suggested items to a given user provided by any black-box GNN-based recommender system. Specifically, for each recommended item, GREASE first trains a surrogate GNN model on the subgraph obtained as the union of the target user-item pair and its l-hop neighborhood. Then, it jointly generates factual and counterfactual explanations by finding optimal adjacency matrix perturbations to capture the sufficient and necessary conditions for the item to be recommended. Experiments on real-world datasets show that GREASE can generate concise and compelling explanations for popular GNN-based recommender models.},
note = {Just Accepted},
journal = {ACM Trans. Recomm. Syst.},
month = may,
keywords = {Graph Neural Networks (GNNs), GNN-based recommender systems, Explainable GNNs, Explainable GNN-based recommendations, Factual explanations, Counterfactual explanations}
}