---
    title: 'Events'

    design:
    # Default section spacing
    spacing: "6rem"

    sections:
    - block: logo
        design:
        css_class: "bg-gray-100 dark:bg-gray-900"
        spacing:
            padding: [0, 0, 0, 0]
            margin: [0, 0, 0, 0]
---

## Workshops
---

### [XAI-KRKG@ECAI2025](https://sites.google.com/unical.it/xai-krkgecai/home-page)
*1st International Workshop on "Explainable AI, Knowledge Representation, and Knowledge Graphs" co-located with ECAI 2025*

The integration of Explainable AI (XAI) with Knowledge Representation (KR) and Knowledge Graphs (KGs) has emerged as a critical field.
Knowledge Representation offers methods for describing, organizing, encoding, and reasoning with knowledge, providing a foundational layer for AI.
Knowledge Graphs, as a seminal result of KR, further enable the structuring of interconnected concepts and relationships, for describing complex domains.
KGs have been effectively used for improving results in different tasks such as question answering, recommendation, and many others.
Together, KR and KGs provide a natural complement to XAI technique.
As AI systems become increasingly embedded in critical domains such as healthcare, finance, and law, the need for interpretable models that offer insights into their reasoning processes has never been more urgent.
By combining XAI with KR and KGs, researchers and practitioners can develop systems that bridge the gap between technical outputs and human comprehension.
This integration not only enhances the clarity and relevance of AI-generated explanations but also supports the development of fairer, more accountable systems by incorporating domain knowledge and logic into the reasoning process.
This workshop seeks to explore the opportunities and challenges at the intersection of XAI, KR, and KGs.
Key themes include leveraging structured knowledge to enhance explainability and interpretability, using XAI methods to refine and validate KR and KG models, as well as to increase trustworthiness of machine learning models and applying these combined approaches to tackle real-world problems.
We invite contributions on theoretical advancements, innovative tools, and case studies that demonstrate how knowledge-driven AI can deliver explanations that are transparent, domain-aware, and user-centric.
By fostering collaboration among researchers, industry practitioners, and domain experts, this workshop aims to drive forward the development of ethical and impactful AI systems that align with human values and societal needs.

### [XAI-KG@ESWC2025](https://xaikg2025.demacs.unical.it/home-page)
*1st International Workshop on "Explainable AI and Knowledge Graphs" co-located with ESWC 2025*

In recent years, the synergy between eXplainable AI (XAI) and Knowledge Graphs (KGs) has gained momentum as an essential approach for achieving transparency, trust, and understanding in AI systems. Knowledge Graphs provide a structured, interconnected framework for representing domain-specific knowledge, while XAI aims either to provide insight for predicted results or to clarify how machine learning models function internally, particularly deep learning systems, which are often complex and difficult to interpret.  By leveraging KGs within XAI, researchers and practitioners can enhance the understanding and interpretability of AI models, enabling explanations that are both contextual and relevant to domain knowledge, making it easier for users to trust and understand AI-driven insights and decisions.
The combination of XAI and KGs presents unique advantages and challenges. KGs can serve as an intuitive map for AI reasoning paths, offering insights into the relationships and logic that AI systems use to reach conclusions. This can be particularly valuable in applications requiring high levels of transparency, such as healthcare, finance, and law, where understanding the rationale behind AI predictions and actions is crucial. Conversely, XAI can assist in constructing and refining KGs, helping to identify which aspects of a graph's structure contribute most to accurate, reliable reasoning, ultimately enriching KG content with a layer of explainable intelligence.
This workshop aims to bring together researchers, practitioners, and industry experts to explore the vast opportunities and specific challenges of combining XAI with KGs. We invite discussion on novel methodologies, applications, and case studies demonstrating how KGs can improve interpretability in complex AI models, and how XAI can, in turn, enhance knowledge extraction, inference, and reasoning within KGs. Topics will span theoretical advances, practical tools, and industry applications, fostering dialogue on how KGs can make black-box AI systems more understandable, and how explainability can guide KG development.  



